#!/bin/bash 
#
# Configure EKS cluster to run Tidepool services
#

set -o pipefail

# set up colors to use for output
function define_colors {
	RED=`tput setaf 1`
	GREEN=`tput setaf 2`
	MAGENTA=`tput setaf 5`
	RESET=`tput sgr0`
}

# irrecoverable error. Show message and exit.
function panic {
	echo "${RED}[✖] ${1}${RESET}"
	exit 1
}

# confirm that previous command succeeded, otherwise panic with message
function expect_success {
	if [ $? -ne 0 ]
	then
		panic $1
	fi
}

# show info message
function info {
	echo "${MAGENTA}[√] ${1}${RESET}"
}

# report that file is being added to config repo
function add_file {
	echo "${GREEN}[ℹ] adding ${1}${RESET}"
}

# report all files added to config repo from list given in stdin
function add_names {
	while read -r line
	do 
		add_file $line
	done
}

# report renaming of file in config repo
function rename_file {
	echo "${GREEN}[√] renaming ${1} ${2}${RESET}"
}

# conform action, else exit
function confirm {
	if [ "$APPROVE" != "true" ]
	then
		local msg=$1
		read -p "${RED}$msg${RESET} " -n 1 -r
		if [[ ! $REPLY =~ ^[Yy]$ ]]
		then
			exit 1
		else
			echo
		fi
	fi
}

# require that REMOTE_REPO env variable exists, expand REMOTE_REPO into full name
function check_remote_repo {

	if [ -z "$REMOTE_REPO" ]
	then
		panic "must provide REMOTE_REPO"
	fi

	if [[ $REMOTE_REPO != git@github.com* ]]
	then
		REMOTE_REPO="git@github.com:tidepool-org/$REMOTE_REPO"
	fi
}

# clean up all temporary files
function cleanup {
	if [ -f "$TMP_DIR" ]
	then
		rm -rf $TMP_DIR
	fi
}


# create temporary workspace to clone Git repos into, change to that directory
function setup_tmpdir {
	if [[ ! -d $TMP_DIR ]]; then
		info "creating tmp dir"
		TMP_DIR=`mktemp -d 2>/dev/null || mktemp -d -t 'TMP_DIR'`
		trap cleanup EXIT
		cd $TMP_DIR
	fi
}

# clone config repo, change to that directory
function clone_remote {
	cd $TMP_DIR
	if [[ ! -d $(basename $REMOTE_REPO) ]]; then
		info "cloning remote"
		git clone $REMOTE_REPO
		expect_success "Cannot clone $REMOTE_REPO"
	fi
	cd $(basename $REMOTE_REPO)
}

# clone quickstart repo, export QUICKSTART_DIR
function set_quickstart_dir {
	if [[ ! -d $QUICKSTART_DIR ]]; then
		info "cloning quickstart"
		pushd $TMP_DIR >/dev/null 2>&1
		git clone git@github.com:/tidepool-org/tidepool-quickstart
		export QUICKSTART_DIR=$(realpath tidepool-quickstart)
		popd >/dev/null 2>&1
	fi
}

# clone development repo, exports DEV_DIR and CHART_DIR
function set_development_dir {
	if [[ ! -d $CHART_DIR ]]; then
		info "cloning development tools"
		pushd $TMP_DIR >/dev/null 2>&1
		git clone git@github.com:/tidepool-org/development
		cd development
       		git checkout k8s
		DEV_DIR=$(realpath .)
		CHART_DIR=${DEV_DIR}/charts/tidepool/0.1.7
		popd >/dev/null 2>&1
	fi
}

# clone secret-map repo, export SM_DIR
function clone_secret_map {
	if [[ ! -d $SM_DIR ]]; then
		info "cloning secret-map"
		pushd $TMP_DIR >/dev/null 2>&1
		git clone git@github.com:/tidepool-org/secret-map
		SM_DIR=$(realpath ./secret-map)
		popd >/dev/null 2>&1
	fi
}

# get values file
function get_config {
	yq r values.yaml -j
}

# retrieve value from values file, or exit it not available
function must_get_value {
	local val=$(yq r values.yaml -j $1 | sed -e 's/"//g' -e "s/'//g")
	if [ $? -ne 0 -o "$val" == "null" -o "$val" == "" ]
	then
		panic "Missing $1 from values.yaml file."
	fi
	echo $val
}

# retrieve name of cluster
function get_cluster {
	must_get_value "cluster.metadata.name"
}

# retrieve name of region
function get_region {
	must_get_value "cluster.metadata.region"
}

# retrieve email address of cluster admin
function get_email {
	must_get_value "email" 
}

# retrieve AWS account number
function get_aws_account {
	must_get_value "aws.accountNumber"
}

# retrieve list of AWS environments to create
function get_environments {
	yq r values.yaml environments | sed -e "/^  .*/d" -e s/:.*//
}

# retrieve list of K8s system masters
function get_iam_users {
	yq r values.yaml aws.iamUsers | sed -e "s/- //" -e 's/"//g'
}

# retrieve bucket name or create from convention
function get_bucket {
	local env = $1
	local bucket=$(yq r values.yaml environments.${env}.asset | sed -e "/^  .*/d" -e s/:.*//)
	if [ "$bucket" == "null" ]
	then
		local cluster=$(get_cluster)
		echo "tidepool-${cluster}-${env}-asset"
	else
		echo $bucket
	fi
}

# create Tidepool assets bucket
function make_assets {
	local env
	for env in $(get_environments)
	do
		local bucket=$(get_bucket $env)
  		info "creating asset bucket $bucket"
  		aws s3 mb s3://$bucket
  		info "copying  dev assets into $bucket"
  		aws s3 cp s3://tidepool-dev-asset s3://$bucket
	done
}

# retrieve helm home
function get_helm_home {
	echo ${HELM_HOME:-~/.helm}
}

# make TLS certificate to allow local helm client to access tiller with TLS
function make_cert {
	local cluster=$(get_cluster)
	local helm_home=$(get_helm_home)

	info "installing helm client cert for cluster $cluster"

	info "retrieving ca.pem from AWS secrets manager"
	aws secretsmanager get-secret-value --secret-id $cluster/flux/ca.pem | jq '.SecretString' | sed -e 's/"//g' \
-e 's/\\n/\
/g' >$TMP_DIR/ca.pem

	expect_success "failed to retrieve ca.pem from AWS secrets manager"

	info "retrieving ca-key.pem from AWS secrets manager"
	aws secretsmanager get-secret-value --secret-id $cluster/flux/ca-key.pem | jq '.SecretString' | sed -e 's/"//g'  \
-e 's/\\n/\
/g' >$TMP_DIR/ca-key.pem

	expect_success  "failed to retrieve ca-key.pem from AWS secrets manager"
	
	local helm_cluster_home=${helm_home}/clusters/$cluster

	info "creating cert in ${helm_cluster_home}"
	local tiller_hostname=tiller-deploy.flux
	local user_name=helm-client

	echo '{"signing":{"default":{"expiry":"43800h","usages":["signing","key encipherment","server auth","client auth"]}}}' > $TMP_DIR/ca-config.json
	echo '{"CN":"'$user_name'","hosts":[""],"key":{"algo":"rsa","size":4096}}' | cfssl gencert \
  	-config=$TMP_DIR/ca-config.json -ca=$TMP_DIR/ca.pem -ca-key=$TMP_DIR/ca-key.pem \
  	-hostname="$tiller_hostname" - | cfssljson -bare $user_name
	
	rm -rf $helm_cluster_home
	mkdir -p $helm_cluster_home
	mv helm-client.pem $helm_cluster_home/cert.pem
	add_file $helm_cluster_home/cert.pem
	mv helm-client-key.pem $helm_cluster_home/key.pem
	rm helm-client.csr
	add_file $helm_cluster_home/key.pem
	cp $TMP_DIR/ca.pem $helm_cluster_home/ca.pem
	add_file $helm_cluster_home/ca.pem
	rm -f $helm_home/{cert.pem,key.pem,ca.pem}
	cp $helm_cluster_home/{cert.pem,key.pem,ca.pem} $helm_home
	
	if [ "$TILLER_NAMESPACE" != "flux"  -o "$HELM_TLS_ENABLE" != "true" ]
	then
    		info "you must do this to use helm:"
    		info "export TILLER_NAMESPACE=flux"
    		info "export HELM_TLS_ENABLE=true"
	fi
}

# config availability of GITHUB TOKEN in environment
function expect_github_token {
	if [ -z "$GITHUB_TOKEN" ]
	then
        	panic "\$GITHUB_TOKEN required."
	fi
}

# retrieve kubeconfig value
function get_kubeconfig {
	kc=$(must_get_value "kubeconfig")
	realpath $(eval "echo $kc")
}

# create EKS cluster using config.yaml file, add kubeconfig.yaml to config repo
function make_cluster {
	local cluster=$(get_cluster)
	info "creating cluster $cluster"

	eksctl create cluster -f config.yaml --kubeconfig ./kubeconfig.yaml
	expect_success "eksctl create cluster failed."
	git pull
	add_file "./kubeconfig.yaml"
}
	
# merge K8s Kubeconfig of cluster into user's kubeconfig file for each switching (see kubectx)
function merge_kubeconfig {
	local localKubeConfig=$(realpath ./kubeconfig.yaml)
	local kubeconfig=$(get_kubeconfig)
	if [ "$kubeconfig" != "$localKubeConfig" ]
	then
    		if [ -f "$kubeconfig" ]
    		then
        		info "merging kubeconfig into $kubeconfig"
        		KUBECONFIG=$kubeconfig:$localKubeConfig kubectl config view --flatten >$TMP_DIR/updated.yaml
        		mv $TMP_DIR/updated.yaml $kubeconfig
    		else
        		mkdir -p $(dirname $kubeconfig)
        		info "creating new $kubeconfig" 
        		cp $localKubeConfig $kubeconfig
    		fi
	fi
}

# confirm that values file exists or panic
function expect_values_exists {
	if [ ! -f values.yaml ]
	then
		panic "No values.yaml file."
	fi
}

# remove computed pkgs 
function reset_config_dir {
	mv values.yaml $TMP_DIR/
	if [ $(ls | wc -l) -ne 0 ]
	then
		confirm "Are you sure that you want to remote prior contents (except values.yaml)?"
		info "resetting config repo"
		rm -rf pkgs 
	fi
	mv $TMP_DIR/values.yaml .
}

# return list of enabled packages
function enabled_pkgs {
	local pkgs=""
	local directory=$1
	local key=$2
	for dir in $(ls $directory)
	do
		local pkg=$(basename $dir)
		local enabled=$(yq r values.yaml $key.${pkg}.enabled)
		if [ "$enabled" == "true" ]
		then
			pkgs="${pkgs} $pkg"
        	fi
	done
	echo $pkgs
}

# make K8s manifest file for shared services given config, path to directory, and prefix to strip
function template_files {
	local config=$1
	local path=$2
	local prefix=$3
	local fullpath
	for fullpath in $(find $path -type f -print)
	do
		local filename=${fullpath#$prefix}
		mkdir -p $(dirname $filename)
		if [ "${filename: -5}" == ".tmpl" ]
		then
			add_file ${filename%.tmpl}
			envtpl $fullpath >${filename%.tmpl}
		elif [ "${filename: -5}" == ".yaml" ]
		then
			add_file $filename
			cp $fullpath $filename
		elif [ "${filename: -8}" == ".jsonnet" ]
		then
			add_file ${filename%.jsonnet}
			jsonnet --tla-code config="$config" $fullpath | yq r - > ${filename%.jsonnet}
		fi
	done
}

# make K8s manifest files for shared services
function make_shared_config {
	info "creating namespaces and package manifests"
	local config=$(get_config)
	template_files "$config" $QUICKSTART_DIR/namespaces $QUICKSTART_DIR/
	local dir
	for dir in $(enabled_pkgs $QUICKSTART_DIR/pkgs pkgs)
	do
		template_files "$config" $QUICKSTART_DIR/pkgs/$dir $QUICKSTART_DIR/
	done
}

# make EKSCTL manifest file
function make_cluster_config {
	local config=$(get_config)
	info "creating eksctl ClusterConfig manifest"
	add_file "config.yaml"
	jsonnet --tla-code config="$config" ${QUICKSTART_DIR}/eksctl/cluster_config.jsonnet | yq r - > config.yaml
}

# make K8s manifests for enviroments given config, path, prefix, and environment name
function environment_template_files {
	local config=$1
	local path=$2
	local prefix=$3
	local env=$4
	for fullpath in $(find $path -type f -print)
	do
		local filename=${fullpath#$prefix}
		local dir=environments/$env/$(dirname $filename)
		local file=$(basename $filename)
		mkdir -p $dir
		if [ "${file: -8}" == ".jsonnet" ]
		then
			add_file $dir/${file%.jsonnet}
			jsonnet --tla-code config="$config" --tla-str namespace=$env $fullpath | yq r - > $dir/${file%.jsonnet}
		fi
	done
}

# make K8s manifests for environments
function make_environment_config {
	local config=$(get_config)
	local env
	for env in $(get_environments)
	do
		info "creating $env environment manifests"
		for dir in $(enabled_pkgs $QUICKSTART_DIR/environments environments.$env)
		do
			environment_template_files "$config" $QUICKSTART_DIR/environments/$dir $QUICKSTART_DIR/environments/ $env
		done
	done
}

# create all K8s manifests and EKSCTL manifest
function make_config {
	info "creating manifests"
	make_shared_config
	make_cluster_config
	make_environment_config
}
	
# persist changes to config repo in GitHub
function save_changes {
	info "saving changes to config repo"
	git add .
	git commit -m "$1"
	git push
}

# confirm cluster exists or exist
function expect_cluster_exists {
	local cluster=$(get_cluster)
	eksctl get cluster --name $cluster
	expect_success "cluster $cluster does not exist."
}

# install flux into cluster
function make_flux {
	local cluster=$(get_cluster)
	local email=$(get_email)
	
	info "installing flux into cluster $cluster"
	EKSCTL_EXPERIMENTAL=true unbuffer eksctl install \
		flux -f config.yaml --git-url=${REMOTE_REPO}.git --git-email=$email --git-label=$cluster  | tee  $TMP_DIR/eksctl.out
	expect_success "eksctl install flux failed."
	git pull
}

# save Certificate Authority key and pem into AWS secrets manager
function save_ca {
	info "saving certificate authority TLS pem and key to AWS secrets manager"
	local cluster=$(get_cluster)
	local dir=$(cat $TMP_DIR/eksctl.out | grep "Public key infrastructure" | sed -e 's/^.*"\(.*\)".*$/\1/')

	aws secretsmanager describe-secret --secret-id $cluster/flux/ca.pem 2>/dev/null
	if [ $? -ne 0 ]
	then
    		aws secretsmanager create-secret --name $cluster/flux/ca.pem --secret-string "$(cat $dir/ca.pem)"
	    	expect_success "failed to create ca.pem to AWS"
    		aws secretsmanager create-secret --name $cluster/flux/ca-key.pem --secret-string "$(cat $dir/ca-key.pem)"
	    	expect_success "failed to create ca-key.pem to AWS"
	else
    		aws secretsmanager update-secret --secret-id $cluster/flux/ca.pem --secret-string "$(cat $dir/ca.pem)"
		expect_success "failed to update ca.pem to AWS"
    		aws secretsmanager update-secret --secret-id $cluster/flux/ca-key.pem --secret-string "$(cat $dir/ca-key.pem)"
		expect_success "failed to update ca-key.pem to AWS"
	fi
}
	
# save deploy key to config repo
function make_key {
	info "authorizing access to ${REMOTE_REPO}"

	local key=$(fluxctl --k8s-fwd-ns=flux identity)
	local reponame="$(echo $REMOTE_REPO | cut -d/ -f2 | sed -e 's/\.git//')"
	local cluster=$(get_cluster)

	curl -X POST -i\
		-H"Authorization: token $GITHUB_TOKEN"\
		--data @- https://api.github.com/repos/tidepool-org/$reponame/keys << EOF
	{
	
		"title" : "flux key for $cluster created by make_flux",
		"key" : "$key",
		"read_only" : false
	}
EOF
}

# update flux and helm operator manifests
function update_flux {
	info "updating flux and flux-helm-operator manifests"

	if [ -f flux/flux-deployment.yaml ]
	then
		yq r flux/flux-deployment.yaml -j > $TMP_DIR/flux.json
		yq r flux/helm-operator-deployment.yaml -j > $TMP_DIR/helm.json
        	jsonnet  --tla-code-file flux="$TMP_DIR/flux.json"  --tla-code-file helm="$TMP_DIR/helm.json" $QUICKSTART_DIR/flux/flux.jsonnet >$TMP_DIR/updated.json

		add_file flux/flux-deployment-updated.yaml
        	yq r $TMP_DIR/updated.json flux >flux/flux-deployment-updated.yaml

		add_file flux/helm-operator-deployment-updated.yaml
        	yq r $TMP_DIR/updated.json helm >flux/helm-operator-deployment-updated.yaml

		rename_file flux/flux-deployment.yaml flux/flux-deployment.yaml.orig
		mv flux/flux-deployment.yaml flux/flux-deployment.yaml.orig

		rename_file flux/helm-operator-deployment.yaml flux/helm-operator-deployment.yaml.orig
		mv flux/helm-operator-deployment.yaml flux/helm-operator-deployment.yaml.orig
	fi
}

# create service mesh
function make_mesh {
	linkerd check --pre
	expect_success "Failed linkerd pre-check."
	info "linkerd check --pre"
	
	mkdir -p linkerd
	add_file "linkerd/linkerd-config.yaml"
	linkerd install config > linkerd/linkerd-config.yaml
	linkerd install config | kubectl apply -f -
	
	linkerd check config
	while [ $? -ne 0 ]
	do
    		sleep 3
    		info  "retrying linkerd check config"
    		linkerd check config
	done
	info "linkerd check config"
	
	add_file "linkerd/linkerd-control-plane.yaml"
	linkerd install control-plane > linkerd/linkerd-control-plane.yaml
	linkerd install control-plane | kubectl apply -f -
	
	linkerd check
	while [ $? -ne 0 ]
	do
    		sleep 3
    		info "retrying linkerd check"
    		linkerd check 
	done
	info "linkerd installed"
}

# get secrets from legacy environments if requested
function get_secrets {
	local cluster=$(get_cluster)
	local env
	for env in $(get_environments)
	do
		local source=$(yq r values.yaml environments.${env}.source)
		if [ "$source" == "null" -o  "$source" == "" ]
		then
			continue
		fi
		if [ "$source" == "dev" -o "$source" == "stg" -o "$source" == "int" -o "$source" == "prd" ]
		then
			$SM_DIR/bin/git_to_map $source | $SM_DIR/bin/map_to_k8s $env 
		else
			panic "Unknown secret source $source"
		fi
	done
}

# create k8s system master users
function make_users {
	local group=system:masters
	local cluster=$(get_cluster)
	local aws_region=$(get_region)
	local aws_account=$(get_account)

	info "adding system masters"
	local user
	for user in $(get_iam_users)
	do
    		local arn=arn:aws:iam::${aws_account}:user/${user}
    		eksctl create iamidentitymapping --region=$aws_region  --role=$arn --group=$group --name=$cluster --username=$user
    		while [ $? -ne 0 ]
    		do
	    		sleep 3
    	    		eksctl create iamidentitymapping --region=$aws_region  --role=$arn --group=$group --name=$cluster --username=$user
			info "retrying eksctl create iamidentitymapping"
    		done
    		info "added $user"
	done
}
	

# confirm that values.yaml file exists
function expect_values_not_exist {
	if [ -f values.yaml ]
	then
        	confirm "Are you sure that you want to overwrite prior contents of values.yaml?"
	fi
}

# create initial values file
function make_values {
	info "creating values.yaml"
	add_file "values.yaml"
	cp $TMP_DIR/tidepool-quickstart/values.yaml .
	${EDITOR:-vi} values.yaml
}

# enter into bash to allow manual editing of config repo
function edit_config {
	info "exit shell when done making changes."
	bash
	confirm "Are you sure you want to commit changes?"
}

# edit values file
function edit_values {
	if [ -f values.yaml ]
	then
        	info "editing values file for repo $REMOTE_REPO"
		${EDITOR:-vi} values.yaml
	else
		panic "values.yaml does not exist."
	fi
}


# generate random secrets 
function randomize_secrets {
	local env
	for env in $(get_environments)
	do
		local file
        	for file in $(find $CHART_DIR -name \*secret.yaml -print)
        	do
                	helm template --namespace $env --set global.secret.generated=true $CHART_DIR  -f  $CHART_DIR/values.yaml -x $file   >$TMP_DIR/x
                	grep "kind" $TMP_DIR/x >/dev/null 2>&1
                	if [ $? -eq 0 ]
                	then
                        	cat $TMP_DIR/x
                	fi
                	rm $TMP_DIR/x
        	done
	done
}

# delete cluster from EKS, including cloudformation templates
function delete_cluster {
	cluster=$(get_cluster)
	confirm "Are you sure that you want to delete cluster $cluster?"
	info "deleting cluster $cluster"
	eksctl delete cluster --name=$cluster
}

# remove service mesh from cluster and config repo
function remove_mesh {
	info "removing linkerd"
	linkerd install --ignore-cluster | kubectl delete -f -
	rm -rf linkerd
}

# install installation tools
function install_tools {
	info "installing tools"
	brew bundle --file=${DEV_DIR}/Brewfile
	pip3 install boto3 --user
	go get github.com/subfuzion/envtpl/...
}

# await deletion of a CloudFormation template that represents a cluster before returning
function await_deletion {
	local cluster=$(get_cluster)
	info "awaiting cluster $cluster deletion"
	aws cloudformation wait stack-delete-complete --stack-name eksctl-${cluster}-cluster
}

# migrate secrets from legacy GitHub repo to AWS secrets manager
function migrate_secrets {
	set -xv
	local cluster=$(get_cluster)
	get_secrets | external_secret upsert $cluster plaintext | separate_files | add_names
}

# show help
function help {
      echo "$0 [-h|--help] (all|tools|values|edit_values|config|edit|cluster|flux|cert|assets|mesh|migrate_secrets|randomize_secrets|upsert_plaintext_secrets|users|deploy_key|delete_cluster|await_deletion|remove_mesh|kubeconfig)*"
      echo 
      echo "tools - install needed tools"
      echo "values - create initial values.yaml file"
      echo "edit_values - open editor to edit values.yaml file"
      echo "config - create K8s manifests and eksctl K8s manifest file"
      echo "edit - open shell with config repo in current directory.  Exit shell to commit changes."
      echo "cluster - create AWS EKS cluster, add system:master USERS"
      echo "flux - install flux GitOps controller, Tiller, client certs for Helm to access Tiller, and deploy key into GitHub"
      echo "cert - regenerate client certs for Helm to access Tiller"
      echo "assets - copy S3 assets to new bucket"
      echo "mesh - install linkerd service mesh"
      echo "migrate_secrets - migrate secrets from legacy GitHub repo to AWS secrets manager"
      echo "randomize_secrets - generate random secrets and persist into AWS secrets manager"
      echo "upsert_plaintext_secrets - read STDIN for plaintext K8s secrets"
      echo "users - add system:master USERS to K8s cluster"
      echo "deploy_key - copy deploy key from Flux to GitHub config repo"
      echo "delete_cluster - initiate deletion of the AWS EKS cluster"
      echo "await_deletion - await completion of deletion of gthe AWS EKS cluster"
      echo "kubeconfig - copy the KUBECONFIG into the local $KUBECONFIG file"
}

if [ $# -eq 0 ]
then
	help
	exit 0
fi

APPROVE=false
PARAMS=""
while (( "$#" )); do
  case "$1" in
    -y|--approve)
      APPROVE=true
      shift 1
      ;;
    -h|--help)
      help
      exit 0
      ;;
    --) # end argument parsing
      shift
      break
      ;;
    -*|--*=) # unsupported flags
      echo "Error: Unsupported flag $1" >&2
      exit 1
      ;;
    *) # preserve positional arguments
      PARAMS="$PARAMS $1"
      shift
      ;;
  esac
done
# set positional arguments in their proper place
eval set -- "$PARAMS"

define_colors
check_remote_repo

for param in $PARAMS
do
	case $param in 
	all)
		expect_github_token
		setup_tmpdir
		clone_remote
		set_quickstart_dir
		set_development_dir
		expect_values_not_exist
                make_values
                save_changes "Added values"
		make_config
                save_changes "Added config packages"
		make_cluster
                merge_kubeconfig
                make_users
                save_changes "Added cluster and users"
		make_mesh
                save_changes "Added linkerd mesh"
                make_flux
                save_ca
                make_cert
                make_key
                update_flux
                save_changes "Added flux"
		clone_secret_map
		migrate_secrets
                save_changes "Added migrated secrets"
		;;
	edit_values)
		setup_tmpdir
		clone_remote
		edit_values
		make_config
		save_changes "Edited values. Updated config."
		;;
	values)
		setup_tmpdir
		clone_remote
		expect_values_not_exist
		set_quickstart_dir
		make_values
		save_changes "Added values"
		;;
	config)
		setup_tmpdir
		clone_remote
		set_quickstart_dir
		set_development_dir
		make_config
		save_changes "Added config packages"
		;;
	cluster)
		setup_tmpdir
		clone_remote
		set_development_dir
		make_cluster
		merge_kubeconfig
		make_users
		save_changes "Added cluster and users"
		;;
	flux)
		expect_github_token
		setup_tmpdir
		clone_remote
		set_quickstart_dir
		set_development_dir
		make_flux
		save_ca
		make_cert
		make_key
		update_flux
		save_changes "Added flux"
		;;
	cert)
		setup_tmpdir
		clone_remote
		set_development_dir
		make_cert
		;;
	assets)
		make_assets
		;;
	mesh)
		setup_tmpdir
		clone_remote
		set_development_dir
		make_mesh
		save_changes "Added linkerd mesh"
		;;
        randomize_secrets)
		setup_tmpdir
		clone_remote
		set_development_dir
		local cluster=$(get_cluster)
		randomize_secrets | external_secret upsert $cluster encoded | separate_files
	        save_changes "Added random secrets"
		;;
	migrate_secrets)
		setup_tmpdir
		clone_remote
		set_development_dir
		clone_secret_map
		migrate_secrets
	        save_changes "Added migrated secrets"
		;;
	upsert_plaintext_secrets)
		setup_tmpdir
		clone_remote
		set_development_dir
		local cluster=$(get_cluster)
		external_secret upsert $cluster plaintext | separate_files | add_names
	        save_changes "Added plaintext secrets"
		;;
	users)
		setup_tmpdir
		clone_remote
		make_users
		;;
	deploy_key)
		setup_tmpdir
		clone_remote
		expect_github_token
		make_key
		;;
	delete_cluster)
		setup_tmpdir
		clone_remote
		local cluster=$(get_cluster)
		delete_cluster
		info "cluster $cluster deletion  takes ~10 minutes to complete"
		;;
	await_deletion)
		setup_tmpdir
		clone_remote
		await_deletion
		info "cluster deleted"
		;;
	remove_mesh)
		setup_tmpdir
		clone_remote
		remove_mesh
		save_changes "Removed mesh."
		;;
	tools)
		install_tools
		info "tools installed"
		;;
	edit)
		setup_tmpdir
		clone_remote
		edit_config
		save_changes "Manual changes."
		;;
	kubeconfig)
		setup_tmpdir
		clone_remote
		merge_kubeconfig
		;;
	esac
done

